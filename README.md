
# ğŸ“˜ README.md

## ğŸ§  Project Overview
This project includes three main components of a Natural Language Processing (NLP) pipeline using different techniques: **Text Classification**, **Summarization**, and **Clustering**. Each notebook tackles a specific NLP task using Hugging Face Transformers and other modern libraries.

---

## ğŸ“ Files Included

### 1. `classification TRUE.ipynb`
ğŸ”¹ **Task**: Text Classification  
ğŸ”¹ **Description**:  
- Loads and preprocesses labeled review data  
- Trains a transformer-based classification model  
- Evaluates performance using standard metrics (accuracy, precision, etc.)  
ğŸ”¹ **Model Used**: Pretrained BERT-like model from Hugging Face  
ğŸ”¹ **Input**: Reviews + Ratings  
ğŸ”¹ **Output**: Predicted sentiment or category  

### 2. `NLP(summrazition).ipynb`
ğŸ”¹ **Task**: Text Summarization  
ğŸ”¹ **Description**:  
- Loads product reviews  
- Filters them by category  
- Uses BART summarization pipeline to generate short summaries  
ğŸ”¹ **Model Used**: `facebook/bart-large-cnn`  
ğŸ”¹ **Input**: Raw review text  
ğŸ”¹ **Output**: Concise summary of reviews  

### 3. `Clustring.ipynb`
ğŸ”¹ **Task**: Clustering / Topic Discovery  
ğŸ”¹ **Description**:  
- Applies vectorization on textual data  
- Performs clustering using KMeans or Hierarchical clustering  
- Evaluates clusters with Silhouette Score  
ğŸ”¹ **Input**: Text data  
ğŸ”¹ **Output**: Grouped topics or document clusters  

---

## ğŸ› ï¸ Requirements

- Python 3.8+
- `transformers`
- `sklearn`
- `pandas`
- `matplotlib`
- `seaborn`
- `scipy`
- `gradio` 

---

## ğŸš€ How to Run

1. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```
2. Open JupyterLab or Jupyter Notebook:
   ```bash
   jupyter lab
   ```
3. Run notebooks in order or independently based on the task:
   - `classification TRUE.ipynb`
   - `NLP(summrazition).ipynb`
   - `CTD.ipynb`
